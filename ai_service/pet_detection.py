"""
PetZone AI Service - Motion Detection & Video Streaming
========================================================
Chá»©c nÄƒng:
1. PhÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng báº±ng Background Subtraction (OpenCV)
2. Stream video real-time qua HTTP Ä‘á»ƒ Frontend hiá»ƒn thá»‹
3. Gá»­i tráº¡ng thÃ¡i phÃ¡t hiá»‡n thÃº cÆ°ng lÃªn Backend .NET API
"""

import cv2
import numpy as np
import requests
import time
from flask import Flask, Response
from threading import Thread
import datetime

# ============ Cáº¤U HÃŒNH ============
BACKEND_API_URL = "http://localhost:5000/api/ai/status"  # Thay Ä‘á»•i theo Backend cá»§a báº¡n
CAMERA_INDEX = 0  # 0 = Webcam máº·c Ä‘á»‹nh
MOTION_THRESHOLD = 500  # Sá»‘ pixel thay Ä‘á»•i Ä‘á»ƒ coi lÃ  cÃ³ chuyá»ƒn Ä‘á»™ng
CHECK_INTERVAL = 3  # Gá»­i API má»—i 3 giÃ¢y
NO_MOTION_TIMEOUT = 10  # Sau 10s khÃ´ng cÃ³ chuyá»ƒn Ä‘á»™ng â†’ Chuá»“ng trá»‘ng

app = Flask(__name__)

# ============ BIáº¾N TOÃ€N Cá»¤C ============
camera = None
output_frame = None
has_pet = False
last_motion_time = time.time()
background_subtractor = None


def init_camera():
    """Khá»Ÿi táº¡o camera"""
    global camera, background_subtractor
    camera = cv2.VideoCapture(CAMERA_INDEX)
    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    # Sá»­ dá»¥ng MOG2 Background Subtractor (tá»‘t hÆ¡n cho motion detection)
    background_subtractor = cv2.createBackgroundSubtractorMOG2(
        history=500,  # Sá»‘ frame lÆ°u lá»‹ch sá»­
        varThreshold=16,  # NgÆ°á»¡ng phÃ¡t hiá»‡n
        detectShadows=True  # Loáº¡i bá» bÃ³ng
    )
    
    print("âœ… Camera khá»Ÿi táº¡o thÃ nh cÃ´ng!")


def detect_motion(frame):
    """
    PhÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng trong frame
    Returns: (cÃ³ chuyá»ƒn Ä‘á»™ng?, frame vá»›i khung váº½)
    """
    global background_subtractor
    
    # Chuyá»ƒn sang grayscale vÃ  lÃ m má» Ä‘á»ƒ giáº£m noise
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (21, 21), 0)
    
    # Ãp dá»¥ng background subtraction
    fg_mask = background_subtractor.apply(gray)
    
    # Loáº¡i bá» bÃ³ng (giÃ¡ trá»‹ 127) vÃ  chá»‰ láº¥y foreground (255)
    _, fg_mask = cv2.threshold(fg_mask, 244, 255, cv2.THRESH_BINARY)
    
    # Morphological operations Ä‘á»ƒ loáº¡i bá» noise
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
    
    # Äáº¿m sá»‘ pixel chuyá»ƒn Ä‘á»™ng
    motion_pixels = cv2.countNonZero(fg_mask)
    
    # TÃ¬m contours (viá»n cá»§a váº­t thá»ƒ chuyá»ƒn Ä‘á»™ng)
    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    motion_detected = False
    annotated_frame = frame.copy()
    
    # Váº½ hÃ¬nh chá»¯ nháº­t quanh vÃ¹ng chuyá»ƒn Ä‘á»™ng
    for contour in contours:
        if cv2.contourArea(contour) > 500:  # Bá» qua vÃ¹ng nhá»
            motion_detected = True
            (x, y, w, h) = cv2.boundingRect(contour)
            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
    
    # Hiá»ƒn thá»‹ thÃ´ng tin lÃªn frame
    status_text = "ğŸŸ¢ PHÃT HIá»†N THÃš CÆ¯NG" if motion_detected else "ğŸ”´ CHUá»’NG TRá»NG"
    color = (0, 255, 0) if motion_detected else (0, 0, 255)
    
    cv2.putText(annotated_frame, status_text, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    cv2.putText(annotated_frame, f"Motion Pixels: {motion_pixels}", (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(annotated_frame, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), 
                (10, annotated_frame.shape[0] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    return motion_detected or motion_pixels > MOTION_THRESHOLD, annotated_frame


def send_status_to_backend(has_pet_status):
    """Gá»­i tráº¡ng thÃ¡i phÃ¡t hiá»‡n lÃªn Backend API"""
    try:
        payload = {
            "hasPet": has_pet_status,
            "detectionMethod": "MotionDetection",
            "timestamp": datetime.datetime.now().isoformat(),
            "confidence": 0.85 if has_pet_status else 0.95
        }
        
        response = requests.post(BACKEND_API_URL, json=payload, timeout=5)
        
        if response.status_code == 200:
            print(f"âœ… ÄÃ£ gá»­i API: hasPet={has_pet_status}")
        else:
            print(f"âš ï¸ API tráº£ vá» lá»—i: {response.status_code}")
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Backend: {e}")


def process_video_stream():
    """Thread xá»­ lÃ½ video vÃ  phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng"""
    global output_frame, has_pet, last_motion_time
    
    last_api_call = time.time()
    
    while True:
        success, frame = camera.read()
        if not success:
            print("âš ï¸ KhÃ´ng thá»ƒ Ä‘á»c frame tá»« camera")
            time.sleep(1)
            continue
        
        # PhÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng
        motion_detected, annotated_frame = detect_motion(frame)
        
        # Cáº­p nháº­t tráº¡ng thÃ¡i
        current_time = time.time()
        if motion_detected:
            has_pet = True
            last_motion_time = current_time
        else:
            # Náº¿u khÃ´ng cÃ³ chuyá»ƒn Ä‘á»™ng trong NO_MOTION_TIMEOUT giÃ¢y
            if current_time - last_motion_time > NO_MOTION_TIMEOUT:
                has_pet = False
        
        # Gá»­i API má»—i CHECK_INTERVAL giÃ¢y
        if current_time - last_api_call >= CHECK_INTERVAL:
            send_status_to_backend(has_pet)
            last_api_call = current_time
        
        # In log ra console
        status_emoji = "ğŸ¾" if has_pet else "â­•"
        status_text = "PhÃ¡t hiá»‡n thÃº cÆ°ng" if has_pet else "Chuá»“ng trá»‘ng"
        print(f"{status_emoji} [{datetime.datetime.now().strftime('%H:%M:%S')}] {status_text}")
        
        # Cáº­p nháº­t frame cho streaming
        output_frame = annotated_frame.copy()


def generate_frames():
    """Generator Ä‘á»ƒ stream video qua HTTP"""
    global output_frame
    
    while True:
        if output_frame is None:
            continue
        
        # Encode frame sang JPEG
        ret, buffer = cv2.imencode('.jpg', output_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        frame_bytes = buffer.tobytes()
        
        # Tráº£ vá» frame dÆ°á»›i dáº¡ng multipart stream
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        
        time.sleep(0.033)  # ~30 FPS


# ============ FLASK ROUTES ============
@app.route('/video_feed')
def video_feed():
    """Endpoint Ä‘á»ƒ Frontend láº¥y video stream"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/status')
def get_status():
    """Endpoint Ä‘á»ƒ Frontend láº¥y tráº¡ng thÃ¡i hiá»‡n táº¡i"""
    return {
        "hasPet": has_pet,
        "lastMotionTime": last_motion_time,
        "timestamp": time.time()
    }


@app.route('/health')
def health():
    """Health check endpoint"""
    return {"status": "running", "camera": camera is not None and camera.isOpened()}


# ============ MAIN ============
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¾ PETZONE AI SERVICE - MOTION DETECTION & STREAMING")
    print("=" * 60)
    
    # Khá»Ÿi táº¡o camera
    init_camera()
    
    # Chá» camera á»•n Ä‘á»‹nh
    print("â³ Äang khá»Ÿi Ä‘á»™ng camera...")
    time.sleep(2)
    
    # Báº¯t Ä‘áº§u thread xá»­ lÃ½ video
    print("ğŸš€ Báº¯t Ä‘áº§u phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng...")
    video_thread = Thread(target=process_video_stream, daemon=True)
    video_thread.start()
    
    # Cháº¡y Flask server
    print("\nğŸ“¡ Video streaming:")
    print(f"   â†’ http://localhost:5001/video_feed")
    print(f"\nğŸ“Š Status API:")
    print(f"   â†’ http://localhost:5001/status")
    print(f"\nğŸ’¡ Backend API: {BACKEND_API_URL}")
    print("\nâ¹ï¸  Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng\n")
    
    try:
        app.run(host='0.0.0.0', port=5001, threaded=True, debug=False)
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Äang dá»«ng AI Service...")
        if camera:
            camera.release()
        print("âœ… ÄÃ£ dá»«ng!")
